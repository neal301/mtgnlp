**DOWNLOAD THE CARD DATA TO YOUR data FOLDER SO EVERYONE'S PATH IS THE SAME**

Vectorization options:
SIMPLER
- TF-IDF 
- count vectorizer
ADVANCED
- doc2vec
- word2vec
- BERT embeddings
- GloVe

model options:
- semantec search
- BERT
- knn w/ euclidian distance


NEAL:
TFIDF, BERT

DAN:
semantec search, GLOVE embeddings, word2vec

TROY:
ELECTRA, 

We need to create a vector database to store the text data once it is vectorized. (unsure if this is some type of special file or something).

HYBRID APPRAOCH:
    This is how we layer on the color, type, and other attributes. Things like color would be used as an initial screen to filter the cards, if there is a secondary attribute or something (like type? cost?) then we could vectorize that if need be (or just change that to a number) and add it to the search. We would weight the relevent pieces to create an overall similarity score.
